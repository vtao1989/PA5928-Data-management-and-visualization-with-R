[
["index.html", "PA 5928 Data Management &amp; Visualization with R (Updating) Chapter 1 Course Syllabus 1.1 Course Description 1.2 Course Prerequisites 1.3 Logistics 1.4 Course Learning Outcomes 1.5 In-class exercise and final project 1.6 Course Schedule (Tentative) 1.7 Homework and projects collaboration and submission policy 1.8 Some results from the online survey", " PA 5928 Data Management &amp; Visualization with R (Updating) Tao Tao (University of Minnesota) 2019-12-10 Chapter 1 Course Syllabus 1.1 Course Description Introduction to RStudio software. Use of RStudio to carry out R file and related dataset management functions. Tools and techniques for data analysis and statistical programming in quantitative research or related applied areas. Topics include data selection, data manipulation, and data visualization (including charts, plots, histograms, maps, and other graphs). 1.2 Course Prerequisites Introductory statistics (regression is not necessary); ability to create bar graphs, line graphs, and scatter plots in MS Excel; and familiarity with principles of data visualization. 1.3 Logistics Instructor: Tao Tao, taotao@umn.edu Location: HHH 85 Time: Starting 10/8: Tuesdays 9:45AM to 11:00AM Office hours: Tuesday from 2:00 pm to 4:00 pm at HHH 271 Canvas: All course notes will be posted in this course website, but links will be provided on Canvas. Canvas will also be used to submit your in-class exercises, final project, and grades. So you only need to pay attention to Canvas to check everything! 1.4 Course Learning Outcomes At the end of this course, students will be able to: Use RStudio to carry out R file and related dataset management Use R to work with different types of datasets and conduct basic data management Use R to visualize data with different types of plots 1.5 In-class exercise and final project An in-class exercise will be assigned during each class for the students to practice what they have learned. ChimeIn will be used in class to check the class performance in a anonymous way. The in-class exercises will be mostly finished during the class time, and students are still required to submit their codes on the same day with necessary notes to indicate their ideas. Students will use the knowledge from this course to complete a final project (data analysis for a interested research question and write a short report about it). Grading policy In-class exercise codes: 60% Final project: 40% 1.6 Course Schedule (Tentative) # Date Topic Notes 1 10/8 Introduction to RStudio Uploaded 2 10/15 Introduction to R Uploaded 3 10/22 Data manipulation with base functions Uploaded 4 10/29 Data manipulation with dplyr Uploaded 5 11/5 Data visualization with base functions Uploaded 6 11/12 Data visualization with ggplot2 Uploaded 7 11/19 Data Exploratory Analysis Uploaded 8 11/26 Spatial Visualization Uploaded 9 12/3 Statistics Uploaded 10 12/10 Revisit Spatial Visualization Updated 1.7 Homework and projects collaboration and submission policy Students can discuss their works with other students, but must code and write up notes by themselves. Plagiarism is not allowed by the university policies. Please do be careful about this. In-class exercises and projects should be submitted through Canvas. If you cannot attend the class, please write a email to the instuctor including a valid reason before the class. Then you can make up the in-class exercise in the following one week after the class. When you communicate the instructor with emails, please include PA 5928 at the beginning of your title. 1.8 Some results from the online survey 1.8.1 Question 1 1.8.2 Question 2 1.8.3 Question 3 "],
["introduction-to-rstudio.html", "Chapter 2 Introduction to RStudio 2.1 What is R 2.2 What is RStudio 2.3 Install R + RStudio 2.4 Familiar with the user interface of RStudio 2.5 Create and save R file 2.6 Print Hello, world 2.7 Install and use R Packages 2.8 Make notes 2.9 Tips", " Chapter 2 Introduction to RStudio In this chapter, we will go through some basic operations of RStudio. 2.1 What is R R is a type of programming language and supports many tasks including statistical computation (data cleaning, data management, statistics, machine learning) and graphics (static plots and interactive plots). You can also use it to create website (like this course website), write papers, analyze texts, etc. The most important thing is that R is free and easy to use, that’s why it has been applied in many fileds. 2.2 What is RStudio RStudio is a programming software for editing and running R code. It has many great features to make R programming easier! 2.3 Install R + RStudio For better coding and running R, you should install both R and RStudio. You could code R with the installation of R only, however, RStudio provides you with more conveinece in coding. In this course, we will use RStudio to do all the course lectures and exercises. So please make sure you install both of them! R could be downloaded here and RStudio could be downloaded here. Both Windows OS (Operating System) and Mac OS are supported, so please choose the right one you need for your own system. (If you have any questions about the installation of R or RStudio, please come to me in the office hours or ask IT for help) Or you could use the computers in the lab when there is no lecture. 2.4 Familiar with the user interface of RStudio Below is a screenshot of the user interface of RStudio. You will find couple of panes/windows with different usages.(Selvam 2019) Menu/Tool Bar Source The pane where you write and edit your codes. Environment/History Environment lists all the variables that you are currently using. History presents the codes you have runned before. Console Console is the original R interactive window. You could run codes and see the results here. Plot/Help Plot window shows the output figures. Help window presents the information of the function or package you are checking. 2.5 Create and save R file Three ways to create a R file in the RStudio: 1. Menu -&gt; File -&gt; New File -&gt; R Script 2. Shortcut: Ctrl + Shift + N 3. Tool Bar -&gt; New file button Also three ways to save R file 1. Menu -&gt; File -&gt; Save 2. Shortcut: Ctrl + S 3. Tool Bar -&gt; Save file button 2.6 Print Hello, world Now, let’s try to code something and run them! Let’s print the very classic “Hello, world!” with print() function. We could run the codes in several ways: Select the codes or put the cursor in the line of your code, and click the Run button located in the right-top position of the source pane. Select the codes or put the cursor in the line of your code, and use shortcut: Ctrl + Enter You could also click the Re-run button near the Run button to re-run the codes you ran last time. print(&#39;Hello, world!&#39;) ## [1] &quot;Hello, world!&quot; Because what we need to output here is a string varible, we have to put them in the quotation mark. Either single quotation or double quotation mark works well. Let’s see another example. print(5928) ## [1] 5928 Here, 5928 is an integer and we do not need to put them in the quotation marks. 2.7 Install and use R Packages R is easy to use because it has many packages with different usages. These packages could help you accomplish some complex tasks with just several lines of codes. Some packages have been already been installed and you could use them directly, which are base packages. However, most of the packages have to be installed before you use them. There are couple of ways you could install a package. Let’s take the gbm package for example. 1. Manu -&gt; Tools -&gt; Install Packages... -&gt; Input the package name -&gt; Click Install button 2. Use the code below: install.packages(&quot;gbm&quot;) After the installation of the package, you have import it with library() function before you use the related functions. library(gbm) ## Loaded gbm 2.1.5 We will spend more time in future classes to explore the various R packages and their different usages. 2.8 Make notes It is important to write notes for your codes. It could help others or even yourself understand your codes easily. Use hash tag to indicate the notes. For example, gbm1 &lt;- gbm(AvgMet~PkAreaH+StpNumH+DisToMin, # formula data=MetM, # dataset var.monotone=c(+1, rep(0,10),rep(0,15)), distribution=&quot;gaussian&quot;, # see the help for other choices n.trees=5000, # number of trees shrinkage=0.001, # shrinkage or learning rate, 0.001 to 0.1 usually work interaction.depth=6, # 1: additive model, 2: two-way interactions, etc. bag.fraction = 0.5, # subsampling fraction, 0.5 is probably best n.minobsinnode = 10, # minimum total weight needed in each node cv.folds = 5) R will not run the codes after hash tags in each line. Please try to write simple but necessary notes for the codes. Keep this as a good habbit and you will thank yourself in the future. 2.9 Tips You could divide your codes into sections by enterting chunks before each sections with the shortcut: Ctrl + Shift + R. This will help you organize your codes. Use ? or help() function to find the related instruction or help page, for example, if you want to find the instruction of library() function, just code ?library or help(library) Both will direct you to the instruction page you are looking for in the help window. References "],
["introduction-to-r.html", "Chapter 3 Introduction to R 3.1 Variable types 3.2 Operations 3.3 Data structures 3.4 Conditional statements 3.5 Loops 3.6 Functions", " Chapter 3 Introduction to R A variable is used to store data including value, vector, data frame, etc, which R could use to manipulate (tutorialspoint 2019b). This chapter introduces variable types, operations between variables, data structures, conditional statements, loops, and functions. Before we start, let’s first see how to name a variable. The valid variable name could be constructed with letters, numbers, the dot character (.), and underline character (_). Besides that, a valid variable name should start with a letter or the dot charater not followed by a number. Examples Validity Discussion var.name ✓ var_name ✓ _var_name ☓ Cannot start with the underline .var_name ✓ var%name ☓ Cannot contain % .2var_name ☓ Cannot use the dot followed by a number to start with a variable name 2var_name ☓ Cannot start with a number 3.1 Variable types There are several types of variables which R could recognise, including character, numeric, integer, logical, and complex (Blischak et al. 2019). The type of one variable is decided by the type of value it stores. We can use class() function to check the type of each variable. Character (also known as strings) v &lt;- &quot;Hello, world!&quot; class(v) ## [1] &quot;character&quot; Numeric (real or decimal number/integer) v &lt;- 59.28 class(v) ## [1] &quot;numeric&quot; Integer (L tells R that this number is an integer) v &lt;- 2L class(v) ## [1] &quot;integer&quot; v &lt;-2 class(v) ## [1] &quot;numeric&quot; Logical (Usually True or false) v &lt;- TRUE class(v) ## [1] &quot;logical&quot; v &lt;- FALSE class(v) ## [1] &quot;logical&quot; Complex (complex number is another type of number, different with real number) v &lt;- 1 + 4i class(v) ## [1] &quot;complex&quot; It is important to know clearly what is the type of the variable you are using since different types of variables may have different methods to deal with. Another caveat is that the outlook of the variable may not show its real variable type. For example, a common situation is that a variable contains numbers could be characters. v &lt;- &quot;59.28&quot; class(v) ## [1] &quot;character&quot; Here, the number has quotation marks outside, which means it has been transferred to type character. Therefore, please be careful about this! 3.2 Operations An operation tells R the mathematical or logical munipulations (tutorialspoint 2019a). 3.2.1 Assignment operations Assignment operators assign values to variables. Left assignment a &lt;- 1 b &lt;&lt;- &quot;Hello, world!&quot; c = c(1, 3, 4) Right assignment 1 -&gt; a 2 -&gt;&gt; b 3.2.2 Arithmetic operations Add 1 + 1 ## [1] 2 Subtract 5 - 3 ## [1] 2 Multiple 3 * 5 ## [1] 15 Divide 5 - 3 ## [1] 2 Power 5 ^ 2 ## [1] 25 5 ** 2 # you can also do like this ## [1] 25 Mode (find the remainder) 5 %% 2 ## [1] 1 3.2.3 Relational operations The relational operators compare the two elements and return a logical value (TRUE or FALSE) Larger 3 &gt; 4 ## [1] FALSE 5 &gt; 3 ## [1] TRUE Smaller 3 &lt; 5 ## [1] TRUE 4 &lt; 2 ## [1] FALSE Equal 4 == 4 ## [1] TRUE 5 == 4 ## [1] FALSE No less than (larger or equal to) 3 &gt;= 4 ## [1] FALSE 3 &gt;= 2 ## [1] TRUE No larger than (samller or equal to) 5 &lt;= 2 ## [1] FALSE 5 &lt;= 5 ## [1] TRUE Not equal 3 != 4 ## [1] TRUE 3 != 3 ## [1] FALSE 3.2.4 Logical operations Logical operators are operations only for logical, numeric, or complex types. Most of the time, we apply them on logical values or variables. For numeric variables, 0 is considered FALSE and non-zero numbers are taken as TRUE (DataMentor 2019). You could use T for TRUE or F for FALSE as abbreviation. Logical And TRUE &amp; TRUE ## [1] TRUE FALSE &amp; TRUE ## [1] FALSE FALSE &amp; FALSE ## [1] FALSE Logical Or TRUE | TRUE ## [1] TRUE FALSE | TRUE ## [1] TRUE FALSE | FALSE ## [1] FALSE Logical Not ! TRUE ## [1] FALSE ! FALSE ## [1] TRUE 3.3 Data structures Variables and values could construct different data structures including vector, matrix, data frame, list, and factor (Kabacoff 2019). Vetor You could create a vetor with c() function. a &lt;- c(5, 9, 2, 8) # create a numeric vector a # show the value of this vetor ## [1] 5 9 2 8 b &lt;- c(&#39;hello&#39;, &#39;world&#39;, &#39;!&#39;) # character vector b ## [1] &quot;hello&quot; &quot;world&quot; &quot;!&quot; c &lt;- c(5, &#39;good&#39;) # if you create a vector containing mixed variable types, such as numeric and character, R will restrict them to be the same variable type, here, character c ## [1] &quot;5&quot; &quot;good&quot; You could select elements in the vetor by using var_name[#]. Please pay attention on how R indexes its elements in the data structure. a[3] # select the 3rd element ## [1] 2 b[1:3] # select from the 1st to the 3rd element ## [1] &quot;hello&quot; &quot;world&quot; &quot;!&quot; c[1] # select the 2nd element ## [1] &quot;5&quot; 1:3 means from 1 to 3, so it actually stands for three numbers here, which are 1, 2, 3. Matrix You could create a matrix using matrix() function. a &lt;- matrix(1:6, # the data to be put in the matrix, here we use numbers from 1 to 6 nrow = 2, # number of rows in the matrix ncol = 3, # number of columns in the matrix byrow = FALSE) # how to put the data in the matrix, FALSE means by columns, TURE means by rows. a ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 For variable selection, the intuitive way is using coordinates. a[2,3] # select the elements in the 2nd row and 3rd column ## [1] 6 You could also select the entire row or column. a[ ,2] # the 2nd column ## [1] 3 4 a[1, ] # the 1st row ## [1] 1 3 5 Data frame Data frame is a frequently-used data type in R. It could include columns with different types of values stored in them. Let’s create a dataframe with mixed variables types using data.frame() function. ID &lt;- c(1:4) # create variable ID Name &lt;- c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;) # create variable Name Score &lt;- c(69.5, 77.5, 81.5, 90) # create variable Score df &lt;- data.frame(ID, Name, Score) # combine the varibles into one data frame called df df ## ID Name Score ## 1 1 A 69.5 ## 2 2 B 77.5 ## 3 3 C 81.5 ## 4 4 D 90.0 We created a data frame stored the students’ ID, name, and their test scores. If we want to select elements from this data frame, there are couple of ways. df[2,3] # 2nd row and 3rd column ## [1] 77.5 df[&#39;ID&#39;] # column of variable ID ## ID ## 1 1 ## 2 2 ## 3 3 ## 4 4 df[c(&#39;ID&#39;, &#39;Score&#39;)] # column of ID and Score ## ID Score ## 1 1 69.5 ## 2 2 77.5 ## 3 3 81.5 ## 4 4 90.0 There is another way to select the column by its name. When you type $ after the name of the data frame, RStudio will list all the variable names in that data frame which makes it easier to choose the variable you want. It is more commonly used. df$Name # column of variable Name ## [1] A B C D ## Levels: A B C D List A list could store mixed types of values, which is different from vetor. a &lt;- list(ID = c(1, 2), Name = c(&#39;A&#39;, &#39;B&#39;), Score = c(69.5, 89)) When you want to select elements from a list, you could do it in a similar way as a vector. However, list does not define row or column, so you cannot use 2-D coordinates to select elements like a data frame. a[1] ## $ID ## [1] 1 2 a[2:3] ## $Name ## [1] &quot;A&quot; &quot;B&quot; ## ## $Score ## [1] 69.5 89.0 Someone might be confusing since list looks silimar to data frame. Here is a good discussion about it. Due to the time limitation, we will not cover this discussion in class. The main idea is that list is more flexible than data frame, while data frame has more restrictions. However, since data frame is more similar to 2-D table structure which is more frequently used in our daily work. We apply data frame more than list. Factor Factor is the nominal variable in R. This type will be very useful when we want to analyze data from different groups, such as gender, school, etc. a &lt;- c(1, 2, 1, 2, 3, 3, 1, 1) class(a) ## [1] &quot;numeric&quot; afactor &lt;- factor(a) class(afactor) ## [1] &quot;factor&quot; 3.4 Conditional statements if (test_expression){ statement_1 } else { statement_2 } If the test_expression returns TRUE, then the codes will go to statement_1, if it returns FALSE, the codes will go to statement_2. You could also omit the else part. if (test_expression){ statement_1 } If the test_expression returns FALSE, the codes will continue to next line. x &lt;- 5 if (x &gt; 3){ print(&#39;x is larger than 3&#39;) } else { print(&#39;x is not larger than 3&#39;) } ## [1] &quot;x is larger than 3&quot; x &lt;- 1 if (x &gt; 3){ print(&#39;x is larger than 3&#39;) } Some other conditional statements include switch, which, etc. 3.5 Loops Loops help us repeat the codes we want to run in more than one times. for loop is the intuitive and commonly-used one. for (range){ statement } range will provide the range for a variable. for (i in 1:3){ print(i) } ## [1] 1 ## [1] 2 ## [1] 3 3.6 Functions Functions are codes have been defined with specific usage. You only need to input some necessary variables and functions will do the tasks and return the result. For example, sum() function could help you add the all the numbers in a vector or dataframe and return the sum. sum(c(1, 4, 10, 5)) ## [1] 20 Another example is mean() function could help you average the numbers in a vector or data frame and return the mean value. mean(c(1, 4, 10, 5)) ## [1] 5 It is important to use the right function to do the right task. To do this, you have to be familiar with the functions you are using. It needs more practice. References "],
["data-manipulation-with-base-functions.html", "Chapter 4 Data Manipulation with Base Functions 4.1 Import and save datasets 4.2 View data 4.3 Data selection 4.4 Conditional selection 4.5 Deal with missing values 4.6 Subset 4.7 Merge two datasets 4.8 Column operation", " Chapter 4 Data Manipulation with Base Functions We will introduce how to manipulate with different datasets using base functions in R. 4.1 Import and save datasets There couple of ways to importing and saving different types of datasets (Quick-R 2019c, 2019a). 4.1.1 Import data CSV file mydata &lt;- read.csv(&#39;c:/mydata.csv&#39;, # file location and name header = TRUE, # read the first sep = &quot;,&quot;) # which type of separation EXCEL file library(readxl) dataset &lt;- read_excel(&#39;c:/mydata.xlsx&#39;, # file location and name sheet = &#39;data&#39;) # name or index of the sheet dta STATA file library(foreign) mydata &lt;- read.dta(&#39;c:/mydata.dta&#39;) # file location and name Here is an easy way to load dataset in RStudio. System tool Besides importing data by codes, you could also import data with the system tool. If this is your first time to use this tool, there may be a process to install the packages depending your options. But don’t worry, RStudio can do it by itself. You just need to click the button to approve the installation. File -&gt; Import dataset -&gt; choose the type of dataset you want to import There are some other options or parameters you could set in the import functions listed above (e.g., specify a variable type or try to skip some of the rows). Sometimes it is sort of complex to do it. So for me, I just do those things after I import the dataset. 4.1.2 Save file CSV file write.csv(df, # data &#39;c:/filename.csv&#39;) # file location and name EXCEL file library(xlsx) write.xlsx(mydata, # data &quot;c:/mydata.xlsx&quot;) # file location and name dta STATA file library(foreign) write.dta(mydata, &quot;c:/mydata.dta&quot;) Usually, it takes less time to save file in CSV and CSV file has a smaller size in storage. 4.1.3 File location As you can see in the examples, you need to specify the location (or path) of the file to make sure that R could find your file in the right position. Usually you could find it by checking the system property of the file. You could aovid this. First put your R file and dataset in the same folder. Then start the R file by double clicking. R will use the folder where the R file locates as the working folder. Then you could only specify the name of the file. This is recommended. Since it will easier for others to check your codes since they do not need to change the path of the file. 4.2 View data You could view the variable names and simple discription in the Environment pane on the right-top position of RStudio. If you want to view more information, clik the variable name and view the variale in new window. Here, we use the built-in dataset mtcars as a example. By importing this dataset, use data() function. data(mtcars) You could also view the data in the new window by View() function. Please pay attention that it is initial-capitalized. View(mtcars) View the first ten observations (rows) in the dataset. stands for double class, which is a subtype of numerical variable type. head(mtcars, n = 10) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 view the last five observations in the dataset. tail(mtcars, n = 5) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.9 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.5 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.5 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.6 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.6 1 1 4 2 List the variables in the dataset (Quick-R 2019b). names(mtcars) ## [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; ## [11] &quot;carb&quot; colnames(mtcars) ## [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; ## [11] &quot;carb&quot; List the structure of the dataset. str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... List the dimentions of the dataset dim(mtcars) ## [1] 32 11 List the number of rows in the dataset nrow(mtcars) ## [1] 32 List the number of columns in the dataset. ncol(mtcars) ## [1] 11 4.3 Data selection Select one column with 5 rows of observations. head(mtcars$mpg, n = 5) # by name ## [1] 21.0 21.0 22.8 21.4 18.7 head(mtcars[1], n = 5) # by index ## mpg ## Mazda RX4 21.0 ## Mazda RX4 Wag 21.0 ## Datsun 710 22.8 ## Hornet 4 Drive 21.4 ## Hornet Sportabout 18.7 Select several columns with 5 rows of observations. head(mtcars[c(&#39;mpg&#39;, &#39;disp&#39;)], n = 5) # by name ## mpg disp ## Mazda RX4 21.0 160 ## Mazda RX4 Wag 21.0 160 ## Datsun 710 22.8 108 ## Hornet 4 Drive 21.4 258 ## Hornet Sportabout 18.7 360 head(mtcars[c(1, 3, 5)], n = 5) # by index ## mpg disp drat ## Mazda RX4 21.0 160 3.90 ## Mazda RX4 Wag 21.0 160 3.90 ## Datsun 710 22.8 108 3.85 ## Hornet 4 Drive 21.4 258 3.08 ## Hornet Sportabout 18.7 360 3.15 Select one row by index mtcars[1,] # by index number ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21 6 160 110 3.9 2.62 16.46 0 1 4 4 mtcars[&#39;Valiant&#39;,] # by name of the index ## mpg cyl disp hp drat wt qsec vs am gear carb ## Valiant 18.1 6 225 105 2.76 3.46 20.22 1 0 3 1 Select several rows mtcars[2:3, ] # by index ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 mtcars[c(1,5,9), ] # by index ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.62 16.46 0 1 4 4 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.44 17.02 0 0 3 2 ## Merc 230 22.8 4 140.8 95 3.92 3.15 22.90 1 0 4 2 mtcars[c(&#39;Valiant&#39;, &#39;Hornet Sportabout&#39;), ] # by name ## mpg cyl disp hp drat wt qsec vs am gear carb ## Valiant 18.1 6 225 105 2.76 3.46 20.22 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.02 0 0 3 2 4.4 Conditional selection mtcars[mtcars$mpg &gt; 25, ] ## mpg cyl disp hp drat wt qsec vs am gear carb ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 mtcars[(mtcars$mpg &gt; 25) &amp; (mtcars$qsec &lt; 19), ] ## mpg cyl disp hp drat wt qsec vs am gear carb ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 mtcars$mpg[mtcars$gear == 4] ## [1] 21.0 21.0 22.8 24.4 22.8 19.2 17.8 32.4 30.4 33.9 27.3 21.4 When you do it like this, you select elements from a vector, you do not need to use comma here. 4.5 Deal with missing values In R, the missing values is presented as NA. Test the existence of missing values with is.na() function. We use an revised old example here. ID &lt;- c(1:4) # create variable ID Name &lt;- c(&#39;A&#39;, NA, &#39;C&#39;, &#39;D&#39;) # create variable Name Score &lt;- c(69.5, 77.5, NA, 90) # create variable Score df &lt;- data.frame(ID, Name, Score) # combine the varibles into one data frame called df is.na(df) ## ID Name Score ## [1,] FALSE FALSE FALSE ## [2,] FALSE TRUE FALSE ## [3,] FALSE FALSE TRUE ## [4,] FALSE FALSE FALSE Assign missing values df$Score[df$Score == 90] &lt;- NA df ## ID Name Score ## 1 1 A 69.5 ## 2 2 &lt;NA&gt; 77.5 ## 3 3 C NA ## 4 4 D NA NAs will influence some functions. mean(df$Score) # get the mean value (does not ignore NA) ## [1] NA mean(df$Score, na.rm=TRUE) # (ignore NA) ## [1] 73.5 Test if the observations in the dataset has NAs. complete.cases(df) ## [1] TRUE FALSE FALSE FALSE Find the observations with no NAs. na.omit(df) ## ID Name Score ## 1 1 A 69.5 4.6 Subset subset() is another way to select the data you want. Select observations with mpg larger than 30. data(mtcars) newdata &lt;- subset(mtcars, mpg &gt; 30) newdata ## mpg cyl disp hp drat wt qsec vs am gear carb ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 Select two columns from the dataset. newdata &lt;- subset(mtcars, select = c(&#39;mpg&#39;, &#39;cyl&#39;)) head(newdata, n = 5) ## mpg cyl ## Mazda RX4 21.0 6 ## Mazda RX4 Wag 21.0 6 ## Datsun 710 22.8 4 ## Hornet 4 Drive 21.4 6 ## Hornet Sportabout 18.7 8 4.7 Merge two datasets merge() function does the same work as vlookup() in excel and ‘Join’ function in ArcGIS. It links two datasets based on their common variable (the variable they both have). ID &lt;- c(1:4) # create variable ID Name &lt;- c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;) # create variable Name Score1 &lt;- c(69.5, 77.5, 99, 90) # create variable Score1 df1 &lt;- data.frame(ID, Name, Score1) # combine the varibles into one data frame called df1 df1 ## ID Name Score1 ## 1 1 A 69.5 ## 2 2 B 77.5 ## 3 3 C 99.0 ## 4 4 D 90.0 Name &lt;- c(&#39;A&#39;, &#39;D&#39;, &#39;C&#39;) # create variable Name Score2 &lt;- c(98, 46, 55) # create variable Score2 df2 &lt;- data.frame(Name, Score2) # combine the varibles into one data frame called df2 df2 ## Name Score2 ## 1 A 98 ## 2 D 46 ## 3 C 55 merge(df1, df2, # dataframes needs to be merged by = &#39;Name&#39;, # name of the column/variable used for merging all.x = TRUE) # keep all observations in the first dataframe after merging ## Name ID Score1 Score2 ## 1 A 1 69.5 98 ## 2 B 2 77.5 NA ## 3 C 3 99.0 55 ## 4 D 4 90.0 46 merge(df1, df2, by = &#39;Name&#39;, all.y = TRUE) # keep all observations in the first dataframe after merging ## Name ID Score1 Score2 ## 1 A 1 69.5 98 ## 2 C 3 99.0 55 ## 3 D 4 90.0 46 You could keep all the observations in both two data frames by set all = TRUE in the function. 4.8 Column operation Column operation or vector operation is a very important idea in R. It applies the operations in two columns or the function in one column directly rather than applies them on each element one by one. ID &lt;- c(1:4) # create variable ID Name &lt;- c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;) # create variable Name Score1 &lt;- c(69.5, 77.5, 99, 90) # create variable Score1 Score2 &lt;- c(98, 46, 55, 70) # create variable Score2 df &lt;- data.frame(ID, Name, Score1, Score2) # combine the varibles into one data frame called df df ## ID Name Score1 Score2 ## 1 1 A 69.5 98 ## 2 2 B 77.5 46 ## 3 3 C 99.0 55 ## 4 4 D 90.0 70 Create a new column in the dataframe to calculate the sum of score 1 and score 2 df$totalsocre &lt;- df$Score1 + df$Score2 df ## ID Name Score1 Score2 totalsocre ## 1 1 A 69.5 98 167.5 ## 2 2 B 77.5 46 123.5 ## 3 3 C 99.0 55 154.0 ## 4 4 D 90.0 70 160.0 Create a new column in the dataframe to calculate the mean of score 1 and score 2 df$meansocre &lt;- (df$Score1 + df$Score2)/2 df ## ID Name Score1 Score2 totalsocre meansocre ## 1 1 A 69.5 98 167.5 83.75 ## 2 2 B 77.5 46 123.5 61.75 ## 3 3 C 99.0 55 154.0 77.00 ## 4 4 D 90.0 70 160.0 80.00 References "],
["data-manipulation-with-dplyr.html", "Chapter 5 Data Manipulation with dplyr 5.1 select() 5.2 filter() 5.3 arrange() 5.4 mutate() 5.5 group_by() and summarise() 5.6 join()", " Chapter 5 Data Manipulation with dplyr In this chapter, we will learn a very popular package dplyr to deal with data manipulation. We will mainly go through its main functions (BiomedicalDataScience 2019; r-project 2019). 5.1 select() Before the lecture, install the package in your machine. install.packages(&#39;dplyr&#39;) Let’s first import the package and the mtcars dataset. library(dplyr) data(mtcars) If we want to select some columns from the dataset. We could use the select() function in dplyr. It is similar to the subset() function, but here, you do not need to use select = c('mpg', 'disp'). You use the names of the columns directly in the function. df &lt;- select(mtcars, # name of the data frame mpg, disp) # column names you want to select head(df, 3) ## mpg disp ## Mazda RX4 21.0 160 ## Mazda RX4 Wag 21.0 160 ## Datsun 710 22.8 108 You could also use the index of the columns. df &lt;- select(mtcars, # name of the data frame c(1, 3)) # index of the columns you want to select head(df, 3) ## mpg disp ## Mazda RX4 21.0 160 ## Mazda RX4 Wag 21.0 160 ## Datsun 710 22.8 108 The codes above is kind of a traditional way to do the work. We start with a function and put parameters in the function. However, this is not the typical way to use dplyr. The codes below is a more dplyr way people use dplyr. We start with the name of the data frame. Then, we put a speical sign %&gt;% called pipe after it. We continue from a new line and write the function we want to use. Besides that, we could add more functions with the pipe operator. For example, only show first three observations with head() functions. mtcars %&gt;% # name of the data frame select(mpg, disp) %&gt;% # select the columns by their names head(3) ## mpg disp ## Mazda RX4 21.0 160 ## Mazda RX4 Wag 21.0 160 ## Datsun 710 22.8 108 We will keep using this fasion in the following lecutre. Besides choosing some columns you want, you could also exclude the column you do not want by putting a negative sign - before the variable. mtcars %&gt;% select(-mpg, -disp) %&gt;% head(3) ## cyl hp drat wt qsec vs am gear carb ## Mazda RX4 6 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 6 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 4 93 3.85 2.320 18.61 1 1 4 1 You could use : to select a range of variables. mtcars %&gt;% select(mpg:hp) %&gt;% # select from mpg to hp in the data frame head(3) ## mpg cyl disp hp ## Mazda RX4 21.0 6 160 110 ## Mazda RX4 Wag 21.0 6 160 110 ## Datsun 710 22.8 4 108 93 5.2 filter() In dplyr, we could use filter() function to select the rows satisfying some conditions. mtcars %&gt;% filter(mpg &gt; 30) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## 2 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 3 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## 4 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 Add more conditions by using , to separate them. mtcars %&gt;% filter(mpg &gt; 30, qsec &lt; 19) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 2 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 5.3 arrange() We could arrange the order of some columns by arrange() functions. mtcars %&gt;% arrange(mpg) %&gt;% # arrange mpg in asceding order head(10) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## 2 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## 3 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## 4 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## 5 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## 6 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## 7 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## 8 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## 9 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## 10 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 Or maybe we want mpg to be in a descending order. Just put a desc() outside the variable. mtcars %&gt;% arrange(desc(mpg)) %&gt;% head(10) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## 2 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## 3 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 4 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## 5 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## 6 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## 7 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## 8 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## 9 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## 10 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 We could put them together by using pipe operators to connect them. mtcars %&gt;% select(gear, mpg) %&gt;% arrange(desc(gear), mpg) %&gt;% head(10) ## gear mpg ## 1 5 15.0 ## 2 5 15.8 ## 3 5 19.7 ## 4 5 26.0 ## 5 5 30.4 ## 6 4 17.8 ## 7 4 19.2 ## 8 4 21.0 ## 9 4 21.0 ## 10 4 21.4 5.4 mutate() We use mutate() to do some calculations within the variables and create a new column to store them. mtcars %&gt;% select(mpg) %&gt;% mutate(kmpg &lt;- mpg * 1.609) %&gt;% head(10) ## mpg kmpg &lt;- mpg * 1.609 ## 1 21.0 33.7890 ## 2 21.0 33.7890 ## 3 22.8 36.6852 ## 4 21.4 34.4326 ## 5 18.7 30.0883 ## 6 18.1 29.1229 ## 7 14.3 23.0087 ## 8 24.4 39.2596 ## 9 22.8 36.6852 ## 10 19.2 30.8928 mtcars %&gt;% select(mpg, wt) %&gt;% mutate(kmpg = mpg * 1.609, lbwt = wt * 1000) %&gt;% head(10) ## mpg wt kmpg lbwt ## 1 21.0 2.620 33.7890 2620 ## 2 21.0 2.875 33.7890 2875 ## 3 22.8 2.320 36.6852 2320 ## 4 21.4 3.215 34.4326 3215 ## 5 18.7 3.440 30.0883 3440 ## 6 18.1 3.460 29.1229 3460 ## 7 14.3 3.570 23.0087 3570 ## 8 24.4 3.190 39.2596 3190 ## 9 22.8 3.150 36.6852 3150 ## 10 19.2 3.440 30.8928 3440 5.5 group_by() and summarise() We use group_by() to do aggregation (group the observations based the values of one or one more columns) work and summarise() to calculate some statistics related to each group. mtcars %&gt;% group_by(gear) %&gt;% summarise(mean_mpg = mean(mpg), max_mpg = max(mpg), total = n()) ## # A tibble: 3 x 4 ## gear mean_mpg max_mpg total ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 3 16.1 21.5 15 ## 2 4 24.5 33.9 12 ## 3 5 21.4 30.4 5 mtcars %&gt;% group_by(gear, am) %&gt;% summarise(mean_mpg = mean(mpg), max_mpg = max(mpg), total = n()) ## # A tibble: 4 x 5 ## # Groups: gear [3] ## gear am mean_mpg max_mpg total ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 3 0 16.1 21.5 15 ## 2 4 0 21.0 24.4 4 ## 3 4 1 26.3 33.9 8 ## 4 5 1 21.4 30.4 5 5.6 join() We could use join() to do the same work of merge(). ID &lt;- c(1:4) # create variable ID Name &lt;- c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;) # create variable Name Score1 &lt;- c(69.5, 77.5, 99, 90) # create variable Score1 df1 &lt;- data.frame(ID, Name, Score1) # combine the varibles into one data frame called df1 df1 ## ID Name Score1 ## 1 1 A 69.5 ## 2 2 B 77.5 ## 3 3 C 99.0 ## 4 4 D 90.0 Name &lt;- c(&#39;A&#39;, &#39;D&#39;, &#39;C&#39;) # create variable Name Score2 &lt;- c(98, 46, 55) # create variable Score2 df2 &lt;- data.frame(Name, Score2) # combine the varibles into one data frame called df2 df2 ## Name Score2 ## 1 A 98 ## 2 D 46 ## 3 C 55 df1 %&gt;% left_join(df2, by = &#39;Name&#39;) ## ID Name Score1 Score2 ## 1 1 A 69.5 98 ## 2 2 B 77.5 NA ## 3 3 C 99.0 55 ## 4 4 D 90.0 46 df1 %&gt;% right_join(df2, by = &#39;Name&#39;) ## ID Name Score1 Score2 ## 1 1 A 69.5 98 ## 2 4 D 90.0 46 ## 3 3 C 99.0 55 Could you tell the difference between left_join() and right_join()? Besides left_join() and right_join(), we have inner_join() (keep only matched observations of two data frames) and full_join() (keep all observations of two data frames). References "],
["data-visualization-with-base-functions.html", "Chapter 6 Data Visualization with Base Functions 6.1 Scatter plot 6.2 Line plot 6.3 Bar plot 6.4 Add more elements in the plots 6.5 Pie chart 6.6 Boxplot 6.7 Color in R", " Chapter 6 Data Visualization with Base Functions We go through the base plotting functions in R in this chapter. 6.1 Scatter plot Scatter plot is a good way to show the distribution of data points. data(mtcars) plot(mtcars$mpg, mtcars$wt) # with first as x, and second as y Or, you could use the variable names directly and indicate the dataset as the codes below. You will get the same result. plot(wt ~ mpg, data = mtcars) # you have to specify the name of the data frame here 6.2 Line plot You could transfer the scatter plot above to a line plot by just adding a type variable to indicate that you are plotting a line. Line plot is good for presenting the trend of a variable changing by time. year &lt;- c(1998:2003) # create variable year sales &lt;- c(500, 600, 650, 700, 400, 550) # create variable sales df &lt;- data.frame(year, sales) # combine the variables into one data frame called df plot(sales ~ year, data = df, type = &#39;l&#39;) # type indicates the line type with l You could also choose another type by changing the value of type, as the one below. plot(sales ~ year, data = df, type = &#39;b&#39;) # b for both line and pint You could use help(plot) to check more styles of the plots. 6.3 Bar plot Bar plot is a good way to compare the values in each year or for each item. You could use barplot() to draw it. barplot(df$sales, names.arg = df$year) # names.org indicates the vector of names to be plotted under each bar 6.4 Add more elements in the plots For a reader-friendly plots, you have to add more information such as titile, labels, and legend. For the plot above, we could use the codes below to make it more informative. barplot(df$sales, names.arg = df$year, main = &#39;Bar plot of the sales for each year from 1998 to 2003&#39;, # add title for the plot xlab = &#39;Year&#39;, # add label tag for the x-axis ylab = &#39;Sales (million dollors)&#39;, # add label for the y-axis ylim = c(0, 1000), # set the range of y axis, you could set the range of x axis with xlim legend = &#39;Sales&#39;) # add lengend name 6.5 Pie chart Pie chart is a good way to show the share of each part. You could use pie() function to draw a pie chart in R. pie(df$sales, # value for each piece labels = df$year, # label for each piece main=&quot;Pie Chart of the Sales in ecah Year&quot;) 6.6 Boxplot Boxplot is also called box-whisker plot. It is to present the distribution of the dataset based on their quartiles. In R, you could use boxplot() to draw a boxplot. t &lt;- c(1, 5, 10, 7, 8, 10, 11, 19) boxplot(t, range = 0) # set range = 0 makes the whiskers reach the samllest and largest values in the dataset t &lt;- c(1, 5, 10, 7, 8, 10, 11, 19) boxplot(t, range = 1) # set range = 1 makes the the whiskers extend to the most extreme data point which is no more than range times the interquartile range from the box 6.7 Color in R You could change the color of the plots by adding col = in the functions. For example. plot(sales ~ year, data = df, type = &#39;b&#39;, col = &#39;YellowGreen&#39;) # specify the name of the color Here is a link where you could find the name of the color. You could also use the hexadecimal color code to indicate the color. For example. barplot(df$sales, names.arg = df$year, main = &#39;Bar plot of the sales for each year from 1998 to 2003&#39;, xlab = &#39;Year&#39;, ylab = &#39;Sales (million dollors)&#39;, legend = &#39;Sales&#39;, col = &#39;#009999&#39;) # use the hexadecimal color code, you need to start it with the hash tag By the same link, you could also find the hexadcimal code for each color. "],
["data-visualization-with-ggplot2.html", "Chapter 7 Data Visualization with ggplot2 7.1 Grammer of Graphics (gg) 7.2 Data, Aesthetics, and Geometries 7.3 Facets 7.4 Statistics 7.5 Coordinates 7.6 Themes", " Chapter 7 Data Visualization with ggplot2 In this chapter, we will learn to use ggplot2 to do data visualization tasks. Before the lecture, please install the package first. install.packages(&quot;ggplot2&quot;) 7.1 Grammer of Graphics (gg) We have grammar for languages. We also have grammar for graphcis. That’s where gg of ggplot2 comes from. For ggplot2, it has seven grammatical elements listed in the table below (DataCamp 2019). Element Description Data The dataset being plotted. Aesthetics The scales onto which we map our data. Geometries The visual elements used for our data. Facets Plotting small multiples. Statistics Representations of our data to aid understanding. Coordinates The space on which the data will be plotted. Themes All non-data ink. Let’s take the codes below as a simple example to show how those different elements work in ggplot2. From this example, we might have a general idea what is each element and how does it work. We will talk about each element in details later. library(ggplot2) data(mtcars) ggplot(mtcars, # Data aes(x = mpg, y = wt)) + # Aesthetics geom_point() + # Geometries facet_grid(. ~ gear) + # Facets stat_smooth(method = &quot;lm&quot;, se = FALSE, col = &quot;blue&quot;) + # Statistics scale_x_continuous(&#39;Miles/(US) gallon&#39;, limits = c(0, 40)) + scale_y_continuous(&#39;Weight (1000 lbs)&#39;, limits = c(0, 7)) + # Coordinates theme_bw() # Themes 7.2 Data, Aesthetics, and Geometries Generally, if you want to draw figures with ggplot2, you need at least three elements, which are data, aesthetics, and geometries. Data is the dataset we want to visualize. Aesthetic specifies the variables and related attributes. Geometry indicates the plot type and related attributes. Take the example above again. We want to visualize the varialbes of mpg and wp (aesthetic) of the dataset mtcars (data) with a scatter plot (geometry). Similar to dplyr, ggplot2 also has its own fashion of coding. We start with the ggplot() function. Please pay attention that there is no 2 in the name of the function. In the function, we first indicate the name of the dataset or data frame. Then we use aes() to indicate the scales we want to map our data. Here, we map mpg to x axis, and wt to y axis. Then we use a plus sign + to connect it to other functions. We are going to draw a scatter plot, so we use geom_point(). ggplot(mtcars, # Data aes(x = mpg, y = wt)) + # Aesthetics geom_point() # Geometries We could see the result and it is following our codes. Based on this plot, we have a overall idea of the relationship between wt and mpg, which is wt has a negative relationship with mpg. This result makes sense to us. If a car is lighter and it could drive farther with the same amount of gasoline. (Please remember that this relationship is just a type of correlation, not causality.) We could add more attributes in the aesthetic element. For example, we could use color to indicate the value of hp by adding col = hp. ggplot(mtcars, aes(x = mpg, y = wt, col = hp)) + geom_point() Now we have more information in the result. While the weight is heavier, the hourse power is stronger. Here, hp is a continous variable, so ggplot2 uses the darkness of the color to indicate the value. However, if we use a categorical varibable or a factor (e.g. binomial variable), ggplot2 will use different colors to show different types. ggplot(mtcars, aes(x = mpg, y = wt, col = factor(am))) + geom_point() Here, am stands for the types of transmission system (0 = automatic, 1 = manual). We use factor() to transfer this variable to a categorical one. ggplot2 uses one color for automatic transmission and another color for mannual transmission. Besides color, there are several other parameters to show different aesthetics of the plots. There are differences between the usages of continuous variable and categorical variable. If you want to map variables in those aesthetics, you have to do it in the aes() function. Parameter Description Continuous variable Categorical variable x x axis position ✓ y y axis position ✓ size Diameter of points, thickness of lines ✓ alpha Transparency ✓ ✓ color Color of dots, outlines of other shapes ✓ ✓ fill Fill colour ✓ ✓ labels Text on a plot or axes ✓ shape Shape of point ✓ linetype Line dash pattern ✓ As for geometries, there are many different types you can use for different plots. For examples, geom_point() for scatter plot, geom_bar() for bar plot, geom_boxplot() for boxplot, etc. Most functions of geometries are self-explained, so you could tell what their usages easily. We all talk about those commonly used geometries such as sactter plot, bar plot, line plot, etc in the following parts. 7.2.1 Scatter plot We use geom_point() to plot scatter plot in R with ggplot2. In the example below, we map mpg to x axis, and wt to y axis. We indicate the transparency by set alpha = hp. The transparency of each point is decided by its value of hp. ggplot(mtcars, aes(x = mpg, y = wt, alpha = hp)) + geom_point() 7.2.2 Bar plot In the example below, we draw a bar plot to show the number of cars with different tansmission systems. In aes(), we only indicate the variable am. R then will count the number for each transimission type. We use geom_bar() to plot it. ggplot(mtcars, aes(x = am)) + geom_bar() Go back to our previous example, which is different from the example above. year &lt;- c(1998:2003) # create variable year sales &lt;- c(500, 600, 650, 700, 400, 550) # create variable sales df &lt;- data.frame(year, sales) # combine the variables into one data frame called df ggplot(df, aes(x = year, y = sales)) + geom_bar(stat = &#39;identity&#39;) # you need to specify stat = &#39;identity&#39; to plot the actual value for each year, not count Or you could use another geometry called geom_col() to do it easily. ggplot(df, aes(x = year, y = sales)) + geom_col() 7.2.3 Line plot To show the usage of line plot in ggplot2, we use a new dataset economics from the ggplot2 package. This dataset is produced from US economic time series data. Use help() to check more information of this dataset. In this example, we use geom_line() to draw a line plot. data(economics) ggplot(economics, aes(x = date, y = unemploy)) + geom_line(col = &#39;Blue&#39;) # indicate the color of the line by setting col = &#39;Blue&#39; In this plot, it shows clearly the temporal trend of the number of unemployed population in the US. There two increase recently starting from 2001 and 2008, which match two economic risks around 2001 and 2008. 7.2.4 Boxplot In the example below, we draw a boxplot for each transmission type. To do this, we map am to the x axis, and mpg to the y axis. We use as.factor() to transfer am to a factor (categorical variable). ggplot(mtcars, aes(x = as.factor(am), y = mpg)) + geom_boxplot() 7.2.5 Pie chart In ggplot2, it is not as intuitive as the base function pie() to draw a pie chart. We use the same example to see the difference. year &lt;- c(1998:2003) # create variable year sales &lt;- c(500, 600, 650, 700, 400, 550) # create variable sales df &lt;- data.frame(year, sales) # combine the variables into one data frame called df ggplot(df, aes(x = &#39;&#39;, y = sales, fill = factor(year))) + geom_bar(width = 1, stat = &#39;identity&#39;) + coord_polar(&#39;y&#39;) # transfer the coordinate system to the polar one Whatggplot2 does here to draw a pie plot is to create a bar plot first. ggplot(df, aes(x = &#39;&#39;, y = sales, fill = factor(year))) + geom_bar(width = 1, stat = &#39;identity&#39;) And then transfer the coordinate system to the polar one. ggplot(df, aes(x = &#39;&#39;, y = sales, fill = factor(year))) + geom_bar(width = 1, stat = &#39;identity&#39;) + coord_polar(&#39;y&#39;) 7.3 Facets If you want to split up your data by one or more variables and plot each subset in one figure, facet is the element you want to use. In the following example, we draw a scatter plot for each number of forward gears. In each plot, we map mpg to the x axis and wt to y axis. The three plots are aligned in a row. p &lt;- ggplot(mtcars, # store the plot result in variable p aes(x = mpg, y = wt)) geom_point() ## geom_point: na.rm = FALSE ## stat_identity: na.rm = FALSE ## position_identity p + facet_grid(. ~ gear) # Facets, for each number of foward gears If we want to align the plots in a column, exchange the position of the varialbe in the function. p + facet_grid(gear ~ .) # Facets, pay attention to the position of gear and the dot sign We could put more variables to split the plots. In the following example, we put one more variable vs in the facet_grid(). p + facet_grid(vs ~ gear) # add vs We could use the margins = T to add more plots showing the aggregation of the plots in each column or row. p + facet_grid(vs ~ gear, margins = T) # add aggregation plots for each row and column We could use labeller = label_both to add more information in the label. p + facet_grid(vs ~ gear, labeller = label_both) # add more info in the label 7.4 Statistics You could fit a line to see the general trend of the scatter plot by adding stat_smooth(). p &lt;- ggplot(mtcars, aes(x = mpg, y = wt)) + geom_point() p + stat_smooth(method = &quot;lm&quot;) # linear line p + stat_smooth(method = &#39;loess&#39;) # non-linear line You could draw a histogram for the dataset. p &lt;- ggplot(mtcars, aes(mpg)) p + geom_histogram(binwidth = 5) # the width of each category is 5 p + geom_histogram(bins = 3) # the number of bins is 3 You could fit a denisty line for the histogram. p + geom_histogram(aes( y = ..density..), binwidth = 3, col = &#39;Black&#39;, fill = &#39;White&#39;) + # use density instead of count geom_density(alpha=.2, fill=&quot;Gray&quot;) Another way to show more statistics about your data is boxplot, which we have been introduced before. p &lt;- ggplot(mtcars, aes(x = factor(gear), y = mpg)) p + geom_boxplot() 7.5 Coordinates While there are many coordinate systems supported by ggplot2, the most commonly used is Cartesian coordinate system, which is the combination of x axis and y axis orthogonally. 7.5.1 Zooming in and out In the following example, we zoom in our plot to a specific area. p &lt;- ggplot(mtcars, aes(x = mpg, y = wt)) + geom_point() p + coord_cartesian(xlim = c(10, 30), ylim = c(2,4)) 7.5.2 Ratio We could change the ratio of the length of a y unit relative to the length of a x unit (\\(\\frac{\\text{y unit}}{\\text{x unit}}\\)). p &lt;- ggplot(mtcars, # Data aes(x = mpg, y = wt)) + # Aesthetics geom_point() p + coord_fixed(ratio = 1) # 1 means x and y axes have the same unit p + coord_fixed(ratio = 5) 7.5.3 Swaping the axes p + coord_flip() ggplot(mtcars, aes(x = as.factor(am), y = mpg)) + geom_boxplot() + coord_flip() ggplot(mtcars, # Data aes(gear)) + # Aesthetics geom_bar() + scale_y_reverse() 7.5.4 Polar coordinate system We touched the polar coordinate system a little bit when drawing a pie chart. ggplot(mtcars, aes(x = &#39;&#39;, fill = factor(gear))) + geom_bar(width = 1) + coord_polar(theta = &#39;y&#39;) We could do this in a different way. ggplot(mtcars, aes(factor(gear))) + geom_bar(width = 1, col = &#39;Black&#39;, fill = &#39;Grey&#39;) + coord_polar() 7.6 Themes ggplot2 is powerful in its flexibility of themes. 7.6.1 Add labels Add labels with labs() function. p &lt;- ggplot(mtcars, aes(x = mpg, y = wt)) + geom_point() p + labs(title = &#39;Plot 1&#39;, # title of the plot subtitle = &#39;Subplot1&#39;, # sub title x = &#39;Miles/(US) gallon&#39;, # x label y = &#39;Weight (1000 lbs)&#39;) # y label Or use ggtitle(), xlab(), and ylab() instead. p + ggtitle(&#39;Plot1&#39;) + xlab(&#39;Miles/(US) gallon&#39;) + # x label ylab(&#39;Weight (1000 lbs)&#39;) # y label 7.6.2 Change ticks Here is an example of changing the ticks for a discrete variable. p &lt;- ggplot(mtcars, aes(x = factor(am), y = mpg)) p + geom_boxplot() + scale_x_discrete(name = &quot;Transmission&quot;, # name of the x axis labels = c(&#39;Automatic&#39;, &#39;Manual&#39;)) # change 0 and 1 to automatic and manaual 7.6.3 theme() function theme() function could help to change the styles of every components of the plots. Here are a few examples about it (ggplot2 2019). p &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point() + labs(title = &#39;Fuel economy declines as weight increases&#39;) p # original plot We could use plot.title to change the style of a title in the plot. In the following exmaple, we change the font size of the title by setting element_text() and making size to be twice larger as the default one. p + theme(plot.title = element_text(size = rel(2))) We could also use absolute value to indicate the size directly. p + theme(plot.title = element_text(size = 15)) We could change the background of the plot by setting the value of plot.background in the theme() function. For example, if we want to change the color, we could set element_rect() and fill = 'red'. p + theme(plot.background = element_rect(fill = &#39;red&#39;)) More specifically, if we want to change the style of the panel, which is the inner part restricted by x and y axes, we could set the value of panel.background. p + theme(panel.background = element_rect(fill = &#39;green&#39;, colour = &#39;red&#39;)) We could set the line type of the panel’s border. p + theme(panel.border = element_rect(linetype = &#39;dashed&#39;, fill = NA)) Change the attributes of the lines for the grid. element_line() stands for the attributes of the lines. p + theme(panel.grid.major = element_line(colour = &#39;black&#39;), panel.grid.minor = element_line(colour = &#39;blue&#39;)) Use element_blank() to remove the themes of the target. p + theme(panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank()) We could put the gridline on the top of our data by setting panel.ontop = TRUE. p + theme( panel.background = element_rect(fill = NA), panel.grid.major = element_line(colour = &#39;Blue&#39;), panel.ontop = TRUE ) Change the line style of the axis. p + theme( axis.line = element_line(size = 3, colour = &#39;red&#39;) ) Change the text style of the axis. p + theme( axis.text = element_text(colour = &#39;Green&#39;, size = 15) ) Change the attributes of the text for the axis ticks. p + theme( axis.ticks = element_line(size = 1.5) ) And y label. p + theme( axis.title.y = element_text(size = rel(1.5), angle = 30) ) Now, let’s see what we could do for the legend. p &lt;- ggplot(mtcars, aes(wt, mpg)) + geom_point(aes(colour = factor(cyl), shape = factor(vs))) + labs( x = &#39;Weight (1000 lbs)&#39;, y = &#39;Fuel economy (mpg)&#39;, colour = &#39;Cylinders&#39;, shape = &#39;Transmission system&#39; ) p Remove the legend by setting its postion as legend.position = 'none'. p + theme( legend.position = &#39;none&#39; ) p + theme( legend.position = &#39;top&#39; ) By setting legend.justification for the legend, we anchor point for positioning legend inside plot (“center” or two-element numeric vector) or the justification according to the plot area when positioned outside the plot p + theme( legend.justification = &#39;top&#39; ) p + theme( legend.position = c(.95, .95), legend.justification = c(&#39;right&#39;, &#39;top&#39;), legend.box.just = &#39;right&#39; ) p + theme( legend.box.background = element_rect(), legend.box.margin = margin(6, 6, 6, 6) ) Set attributes for the key of the legend. p + theme( legend.key = element_rect(fill = &#39;white&#39;, colour = &#39;black&#39;) ) Set attributes for the text of the legend. p + theme( legend.text = element_text(size = 8, colour = &#39;red&#39;, face = &#39;bold&#39;) ) If you do not like to customize the theme one element by one element. ggplot2 also provides some function which give you a complete theme. For example, the theme_bw() we used at the start of this lecture. p + theme_bw() p + theme_minimal() p + theme_dark() Please check here for more complete theme. References "],
["exploratory-data-analysis.html", "Chapter 8 Exploratory Data Analysis 8.1 Introduction of the dataset and research question 8.2 Data munipulation 8.3 Data visualization 8.4 Combine them togethor 8.5 More examples 8.6 More more example", " Chapter 8 Exploratory Data Analysis We are going to use what we have learnt so far to do some exploratory data analysis, which is also the practice for data manipulation and visualization. 8.1 Introduction of the dataset and research question The dataset we used here is from the General Social Survey (GSS) carried out by the National Opinion Research Center of the University of Chicago. The dataset shows the results of the vocabulary tests for several years. It contains eight variables (Arel-Bundock 2019). Their descriptions are listed below. Variable Descriptions year The test year gender Gender nativeBorn Was the respondent born in the US? ageGroup Grouped age of the respondent educGroup Grouped education level of the respondent vocab Number of words out of 10 correct on a vocabulary test age Age of the respondent in years educ Years of education of the respondent Our research question is how do the average vocabulary test results change over time? Let’s get start. We first library the packages we need for this task. library(dplyr) library(ggplot2) library(readr) 8.2 Data munipulation We could the import tool to import our dataset and copy the code. GSSvocab &lt;- read_csv(&quot;GSSvocab.csv&quot;) ## Warning: Missing column names filled in: &#39;X1&#39; [1] ## Parsed with column specification: ## cols( ## X1 = col_double(), ## year = col_double(), ## gender = col_character(), ## nativeBorn = col_character(), ## ageGroup = col_character(), ## educGroup = col_character(), ## vocab = col_double(), ## age = col_double(), ## educ = col_double() ## ) There are some warning messages when we import the dataset. The reason for this warning message is that we did not specify the type of the variables. Therefore, R tries to give every variable a type based on its own understanding of the data. Let’s check the dataset to see what it looks like. head(GSSvocab, 5) ## # A tibble: 5 x 9 ## X1 year gender nativeBorn ageGroup educGroup vocab age educ ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1978. 1978 female yes 50-59 12 yrs 10 52 12 ## 2 1978. 1978 female yes 60+ &lt;12 yrs 6 74 9 ## 3 1978. 1978 male yes 30-39 &lt;12 yrs 4 35 10 ## 4 1978. 1978 female yes 50-59 12 yrs 9 50 12 ## 5 1978. 1978 female yes 40-49 12 yrs 6 41 12 Except the first variable, all other variables seem to be imported in the right type. Since the first variable is not useful for our data analysis, we do not need to care about it. Then, based on the initial research questions, we need to calculate the average vocabulary test results for each year. We apply the group_by() function here. year_vocab &lt;- GSSvocab %&gt;% group_by(year) %&gt;% summarize(avgVocab = mean(vocab, na.rm = T)) # indicate na.rm = T to deal with missing value head(year_vocab, 5) ## # A tibble: 5 x 2 ## year avgVocab ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1978 5.96 ## 2 1982 5.74 ## 3 1984 6.02 ## 4 1987 5.74 ## 5 1988 5.82 8.3 Data visualization Then, we apply ggplot() to visualize the dataset year_vocab we have just generated. ggplot(year_vocab, aes(x = year, y = avgVocab)) + geom_line() For a complete plot, we have to add more infomation such as title, x label, and y label, etc. ggplot(year_vocab, aes(x = year, y = avgVocab)) + geom_line() + labs(title = &#39;Average vocabulary test result for each year&#39;, y = &#39;Average vocabulary test score&#39;, x = &#39;Year&#39;) + theme(plot.title = element_text(size = 20), axis.text = element_text(size = 10, colour = &#39;black&#39;), axis.title = element_text(size = 12)) 8.4 Combine them togethor We could put those codes together. GSSvocab %&gt;% group_by(year) %&gt;% summarize(avgVocab = mean(vocab, na.rm = T)) %&gt;% ggplot(aes(x = year, y = avgVocab)) + # we do not put name of the dataset here geom_line() + labs(title = &#39;Average vocabulary test result for each year&#39;, y = &#39;Average vocabulary test score&#39;, x = &#39;Year&#39;) + theme(plot.title = element_text(size = 20), axis.text = element_text(size = 10, colour = &#39;black&#39;), axis.title = element_text(size = 12)) 8.5 More examples Let’s make the research more challenging. Let’s study the topic that how do the average vocabulary test results for male and female change over time? year_gender_vocab &lt;- GSSvocab %&gt;% group_by(year, gender) %&gt;% summarize(avgVocab = mean(vocab, na.rm = T)) head(year_gender_vocab, 5) ## # A tibble: 5 x 3 ## # Groups: year [3] ## year gender avgVocab ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1978 female 6.02 ## 2 1978 male 5.89 ## 3 1982 female 5.76 ## 4 1982 male 5.71 ## 5 1984 female 6.07 ggplot(year_gender_vocab, aes(x = year, y = avgVocab, col = gender)) + geom_line() + labs(title = &#39;Average vocabulary test result for male and female in each year&#39;, y = &#39;Average vocabulary test score&#39;, x = &#39;Year&#39;) + theme(plot.title = element_text(size = 15), axis.text = element_text(size = 10, colour = &#39;black&#39;), axis.title = element_text(size = 12)) Again, we could put them together. GSSvocab %&gt;% group_by(year, gender) %&gt;% summarize(avgVocab = mean(vocab, na.rm = T)) %&gt;% ggplot(aes(x = year, y = avgVocab, col = gender)) + geom_line() + labs(title = &#39;Average vocabulary test result for male and female in each year&#39;, y = &#39;Average vocabulary test score&#39;, x = &#39;Year&#39;) + theme(plot.title = element_text(size = 15), axis.text = element_text(size = 10, colour = &#39;black&#39;), axis.title = element_text(size = 12)) 8.6 More more example We could also do the same thing to each age group and even plot them in different plots with facet_wrap() function. GSSvocab %&gt;% group_by(year, ageGroup) %&gt;% filter(!is.na(ageGroup)) %&gt;% # delete the the obs with missing values in ageGroup summarize(avgVocab = mean(vocab, na.rm = T)) %&gt;% ggplot(aes(x = year, y = avgVocab)) + geom_line() + facet_wrap(~ageGroup, labeller = label_both) + labs(title = &#39;Average vocabulary test result for different age group in each year&#39;, y = &#39;Average vocabulary test score&#39;, x = &#39;Year&#39;) + theme(plot.title = element_text(size = 15), axis.text = element_text(size = 10, colour = &#39;black&#39;), axis.title = element_text(size = 12)) Or boxplots. GSSvocab %&gt;% filter(!is.na(ageGroup)) %&gt;% ggplot(aes(x = ageGroup, y = vocab)) + geom_boxplot() + facet_wrap(~year) + theme(axis.text.x = element_text(angle = 90)) ## Warning: Removed 1319 rows containing non-finite values (stat_boxplot). Or bar plots. GSSvocab %&gt;% filter(!is.na(ageGroup)) %&gt;% group_by(ageGroup, year) %&gt;% summarize(avgVocab = mean(vocab, na.rm = T)) %&gt;% ggplot(aes(x = ageGroup, y = avgVocab)) + geom_col() + facet_wrap(~year) + theme(axis.text.x = element_text(angle = 90)) References "],
["spatial-data-visualization.html", "Chapter 9 Spatial Data Visualization 9.1 Why spatial visualization with R? 9.2 Some basics about spatial data 9.3 Read files 9.4 Deal with spatial data like data frame 9.5 Data management 9.6 Spatial data visualization 9.7 More example 9.8 Add other layers to the current plot 9.9 Geospatial data analysis", " Chapter 9 Spatial Data Visualization In this chapter, we will learn how to deal with the geospatial dataset with packages sf. We will also interact it with ggplot2. Link for the slides of this lecutre. 9.1 Why spatial visualization with R? The common solutions for creating maps include several GIS (Geographic Information System) softwares: ArcGIS, QGIS, etc. They are powerful in spatial data visualization and analysis. However, they do have some disadvantages, such as the workflow is not easy to reproduce, not good at statistical computing, etc. As R has more and more powerful packages that could deal with geospatial data, many researchers and practitioners start to use R in their work. Comparing ArcGIS (or QGIS) with R, is similiar with comparing Stata with R. Both of them have pros and cons. Whether or not you use them depends on your personal perference and task requirements. Then when we should use R to do spatial data visualization, not ArcGIS? Well, one situation is that you do not have access to ArcGIS (ArcGIS is not free), then R is a good choice for you. Another situation could be that you have used R for your data analysis and then you could continue to use R to do spatial visualization. You do not need to change the working environment in this case. Or if you want to make your work more reproducible, R is a good choice since its codes can be recycled for other similar work and you could check your codes to track your data analysis history. 9.2 Some basics about spatial data Spatial data has some differences with our common data. The largest one is that it has spatial attributes for indicate locations. Those spatial attributes could be points, lines, or/and ploygon. It could also be the combination of these elements. Points could be the positions for a single-family house, an intersection, a bar, etc. Lines could be the segments streets, rivers, etc. Polygons could be the boundaries states, counties, cities, etc. As shown in the figure below Source. While they are different spatial attributes, they are all combined with points. For a spatial data file in R, it is similar to the common dataset. It is a 2-D table with each column for a variable. The spatial data also has a column called geometry. This is the variable indicating the spatial attributes. For example, for a spatial file including the points of several cities in Minnesota. Its geometry column will be the longitudes and latitudes of those points. If a spatial file contains the boundaries of the states in the U.S., then its geometry column will be the locations of the polygons. If a sptial data has the information of points, it is called point spatial data. If a spatial data has the information of lines, it is called line spatial data. If a spatial data has the information of polygons, it is called polygon data. A spatial data file can only include one type of spatial attribute. For all geospatial varialbes, they should have a very important information called coordinate reference system (CRS). We will not expand the concept in this lecture. The simple idea is that it is the system to locate geographical entities. For example, you could use longitude and latitude to locate the position of everything on earth, which is a 3D sphere. Or you could use another type of CRS to locate the position of something in a 2D flattened map, as shown in the figure below (Source). For the a same position, its indices will be different in different CRSs. There are two formats of CRS. One is EPSG and the other is proj4string. EPSG is a conbination of numbers. proj4string contains variables and values. You could find more information about them in this link. After reviewing some concepts for geospatial data. Let’s write some codes in R. Before start, let’s install the package first. install.packages(&#39;sf&#39;) And import the package. library(sf) ## Linking to GEOS 3.6.1, GDAL 2.2.3, PROJ 4.9.3 9.3 Read files The file format to store the spatial data is shapefile. We could import the shapefile with st_read() function into R. The dataset is from the Minnesota Geospatial Commons. It contains the geospatial information of the census tracts of the Twin Cities metro area. map &lt;- st_read(&#39;Census2010RealignTract.shp&#39;) ## Reading layer `Census2010RealignTract&#39; from data source `C:\\UMN\\Course\\R_course\\PA5928-Data-management-and-visualization-with-R\\Census2010RealignTract.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 708 features and 10 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 419967.5 ymin: 4924224 xmax: 521254.7 ymax: 5029010 ## epsg (SRID): 26915 ## proj4string: +proj=utm +zone=15 +datum=NAD83 +units=m +no_defs After running the codes, the console has shown some information about the shapefile we just read. class(map) ## [1] &quot;sf&quot; &quot;data.frame&quot; With class(), we could check the type of the variable. It is both sf and data.frame. sf means the dataset is a type of geospatial data and contains some related information. data.frame means that the dataset is also a data frame and could be managed by many functions working on data frames. head(map) ## Simple feature collection with 6 features and 10 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 427577.5 ymin: 4924224 xmax: 516478.2 ymax: 4949418 ## epsg (SRID): 26915 ## proj4string: +proj=utm +zone=15 +datum=NAD83 +units=m +no_defs ## TRACT STATE CO TRACTCE10 GEOID ALAND10 AWATER10 Acres ## 1 61502 27 037 061502 27037061502 149642919 4668565 38134.50 ## 2 61402 27 037 061402 27037061402 211963640 3786753 53258.86 ## 3 81200 27 139 081200 27139081200 90667239 3288582 23205.13 ## 4 61501 27 037 061501 27037061501 168761402 1932931 42132.88 ## 5 81100 27 139 081100 27139081100 183756089 3059699 46115.82 ## 6 81300 27 139 081300 27139081300 218177258 3688572 55189.04 ## Shape_Leng Shape_Area geometry ## 1 54449.32 154324840 POLYGON ((477636.4 4932330,... ## 2 66036.81 215530975 POLYGON ((496883.5 4929115,... ## 3 38782.40 93907812 POLYGON ((448700 4932487, 4... ## 4 65971.67 170505702 POLYGON ((496863.3 4932245,... ## 5 58071.16 186624108 POLYGON ((458497.9 4932388,... ## 6 94116.03 223342132 POLYGON ((439064.1 4943284,... With head(), we could see that there is a column called geometry. Every sf file will have this column, where stores the geospatial information of the observations. Other columns are just normal columns containing information for the observations. We could use st_crs() to check the CRS of the variable. st_crs(map) ## Coordinate Reference System: ## EPSG: 26915 ## proj4string: &quot;+proj=utm +zone=15 +datum=NAD83 +units=m +no_defs&quot; Luckily, this variable contains the right CRS. For the maps in the area of Minnesota, the CRS is the one showing above, 26915 for EPSG. However, sometimes, the file does not have CRS information. You have to check the original source of the file and assign the right CRS to it. st_crs(map) &lt;- 26915 ## Warning: st_crs&lt;- : replacing crs does not reproject data; use st_transform ## for that By doing this, there is a message telling that this function will not do the transformation for us. Sometimes, even if the file contains the right CRS, its CRS might be different from other files. If you want to map them in the same page or want to do geospatial data analysis among them, you have to transfer the CRSs of them to the same one. You could do this by using st_transform(). We could use ggplot2 to visualize the map. For simply mapping the polygons, we do not need to speficify aes(). And we use geom_sf() to plot map. library(ggplot2) ggplot(map) + geom_sf() 9.4 Deal with spatial data like data frame As the spatial data is also a data frame in R. We could use dplyr to deal with it. For example, select the column we want. The current spatial data map contains some variables we do not need, so we could select the useful ones by using select() function in dplyr. Please pay attention that we do not need to select the geometry column. It will be selected automatically. In this lecture, we only select GEOID, which is the ID for each area/tract. library(dplyr) new_map &lt;- map %&gt;% select(GEOID) We could join other data to the current geospatial variable by the join functions in dplyr. Firstly, we import the data. library(readr) data &lt;- read_csv(&#39;data.csv&#39;) ## Parsed with column specification: ## cols( ## GEOID = col_double(), ## POPTOTAL = col_double(), ## HHTOTAL = col_double(), ## AGEUNDER18 = col_double(), ## AGE18_39 = col_double(), ## AGE40_64 = col_double(), ## AGE65UP = col_double() ## ) This dataset also has a variable called GEOID, which could be used to do the join operation. The list below presents the descriptions of other variables, which are all from 2012-2016 five-year ACS estimates. Variable Descriptions GEOID Unique identifier used by Census FactFinder website POPTOTAL Total population HHTOTAL Total households AGEUNDER18 Population age under 18 AGE18_39 Population in this range AGE40_64 Population in this range AGE65UP Populationage 65+ class(new_map$GEOID) ## [1] &quot;factor&quot; class(data$GEOID) ## [1] &quot;numeric&quot; We could join this data to the map by using the GEOID column. Before join operation, we have to transfer the GEOID to match the data type of GEOID in the map file. Currently, their types are different, one is factor and other is numeric. They have to be the same data type before joining. data &lt;- data %&gt;% mutate(GEOID = factor(GEOID)) Then, we do the join operation. new_map &lt;- new_map %&gt;% left_join(data, by = &#39;GEOID&#39;) ## Warning: Column `GEOID` joining factors with different levels, coercing to ## character vector This message tells us that the levels of factors in the GEOIDs of the two files are different. This makes sense, since the data file has more observations, which also will have more levels. 9.5 Data management We calculate the percentage of old people in each census tract. new_map &lt;- new_map %&gt;% mutate(old_percent = AGE65UP/POPTOTAL) 9.6 Spatial data visualization We could use ggplot2 by its geom_sf() function. p &lt;- ggplot(new_map, aes(fill = old_percent)) + # use fill to indicate the variable you want to visualize geom_sf() p The color is not good, we could add scale_fill_gradient() to specify the colours we want. p + scale_fill_gradient(low = &#39;white&#39;, high = &#39;red&#39;) Again, we could add more information to make the figure better and more readable, and change the theme a little bit. p + scale_fill_gradient(low = &#39;white&#39;, high = &#39;red&#39;) + labs(title = &#39;Distribution of old population in the Twin Cities area&#39;, fill = &#39;Percentage&#39;) + theme_bw() Finally, we could use ggsave() to save the plot we want after we run the ggplot() function. 9.7 More example We could visualize the population directly in the map with ggplot2. ggplot(new_map, aes(fill = POPTOTAL)) + geom_sf(colour = &#39;White&#39;) + scale_fill_gradient(low = &#39;white&#39;, high = &#39;Orange&#39;) + labs(title = &#39;Distribution of population in the Twin Cities area&#39;, fill = &#39;Population&#39;) + theme_bw() 9.8 Add other layers to the current plot We could add other layers to the current plot. We import the spatial data of the transit routes in the metro area. transit_route &lt;- st_read(&#39;TransitRoutes.shp&#39;) ## Reading layer `TransitRoutes&#39; from data source `C:\\UMN\\Course\\R_course\\PA5928-Data-management-and-visualization-with-R\\TransitRoutes.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 227 features and 32 fields ## geometry type: MULTILINESTRING ## dimension: XY ## bbox: xmin: 409591 ymin: 4947433 xmax: 515317.7 ymax: 5046090 ## epsg (SRID): 26915 ## proj4string: +proj=utm +zone=15 +datum=NAD83 +units=m +no_defs We add the transit route layers to the current plot by adding one more geom_sf(). ggplot(new_map) + geom_sf() + geom_sf(data = transit_route) Add titles and themes to it. ggplot(new_map) + geom_sf(fill = NA, colour = &#39;Grey&#39;) + geom_sf(data = transit_route, colour = &#39;Blue&#39;) + labs(title = &#39;Transit route in the Twin Cities Metro area&#39;) + theme_bw() 9.9 Geospatial data analysis For those who are familiar with geospatial operations in ArcGIS, sf also provides functions to do geospatial data analysis, such as spatial join, intersect, clip, etc. For example, you could use st_join() to carry out spatial join, use st_intersects() to do intersect, and st_intersection() to do clip. You could find more here. "],
["statistics-in-r.html", "Chapter 10 Statistics in R 10.1 Simple statistics 10.2 Linear regression 10.3 Logistic regression", " Chapter 10 Statistics in R In this chapter, we are going to use R to do some math work. 10.1 Simple statistics We have touched some of the functions in this topic. For example, we could use mean() to compute the average value of a set of numbers. 10.1.1 Mean and median We could use the base functions to do some simple statistical analysis directly. a &lt;- c(10, 20, 30, 50, 33, 29, 10, 30, 100, 0, 4.5) mean(a) # mean ## [1] 28.77273 median(a) # median ## [1] 29 10.1.2 Minimum and maximum value min(a) # minimum value ## [1] 0 max(a) # maximum value ## [1] 100 10.1.3 Quantiles x &lt;- quantile(a) x # list of quantiles ## 0% 25% 50% 75% 100% ## 0.0 10.0 29.0 31.5 100.0 x[2] # select the value by its index ## 25% ## 10 You could add value from 0 to 1 in the quantile() to find a specific value, for example, 40%. quantile(a, 0.4) # 40% of the dataset ## 40% ## 20 10.2 Linear regression Before we start, let’s review some related knowledge first. Regression is used to examine the linear relationships between the dependent variable and independent variables, where dependent variable is the one to be explained and independent variables (also called regressors, predictors, explanatory variables) are those may have influences on the dependent variable. For example, the dependent variable is personal income, and the independent variables are education, gender, age, etc. Among those independent variables, there are two types, one is continuous variable and the other is dummy variable. Continous variable is variable with continuous values, such as income and age. Dummy variable is variable with values of 0 and 1. For example, gender, and people could use 1 for male, and 0 for female. Suppose we have a dependent variable \\(Y\\), and two independent variables \\(X_1\\) and \\(X_2\\), the regression model in assumption could be expressed as below, \\[Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\epsilon\\]. Where, \\(\\beta_0\\) is the intercept, \\(\\beta_1\\) and \\(\\beta_2\\) are coefficients for \\(X_1\\) and \\(X_2\\), \\(\\epsilon\\) is the error term which is the part of the dependent variable which cannot be explained by the intercept and independent variables. The target of regression is to estimate the value of \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\), and test their significance. The coefficients for the independent variables stand for that if the independent variable change one unit, the dependent variable will change the amount of the coefficients. The estimated model could be expressed as, \\[\\hat{Y} = \\hat{\\beta_0} + \\hat{\\beta_1}X_1 + \\hat{\\beta_2}X_2\\] Those variables with hat are estimated variables. While regression provides the estimated values of intercepts and coefficients, it also provides the significance of these estimates with p-values. When p-value is smaller, the estimates tend to be more significant. In R, the function will use some marks to indicate the sinificance levels. The significance level is the probability that the estimates are ‘true’. Mark Descriptions of significance level . 90% * 95% ** 99% *** 99.9% To quantify the fitness of the model, we use \\(R^2\\) with value from 0 to 1. While \\(R^2\\) is close to 1, the model is good and fits the dataset well. \\(R^2\\) has a property that when adding more independent variables in the regression model, the \\(R^2\\) will increase. There is another index called adjusted \\(R^2\\), which considers the number of variables in the models. Our example is the dataset mtcars, and we want to explore the relationship between mpg (Miles/(US) gallon) and wt (Weight (1000 lbs)). Let’s draw a scatter plot to see their distribution. data(mtcars) library(ggplot2) ggplot(mtcars, aes(mpg, wt)) + geom_point() Based on the plot, it seems there is a linear relatitonship between these two variables. We then add a linear line to fit them with geom_smooth() in ggplot2. ggplot(mtcars, aes(mpg, wt)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = F) Most of the points are near the fitted linear line. To quantify this linear relaitonship, We could use lm() function to fit this linear relationship and use summary() function to see the result. In the function, the formula indicates the model in assumpiton. Here, our model in assumpiton is, \\[mpg = \\beta_0 + \\beta_1 \\times wt + \\epsilon\\] When we code this model in R, we do mpg ~ wt ## mpg ~ wt We only need to write down the variable names of the dependent variable and independent variables, and use ~ to connect them. No need to write the intercept and error term. We also need to indicate the name of the dataset in the function. lm_fit &lt;- lm(mpg ~ wt, # formula data = mtcars) # dataset summary(lm_fit) # check result ## ## Call: ## lm(formula = mpg ~ wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.5432 -2.3647 -0.1252 1.4096 6.8727 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.2851 1.8776 19.858 &lt; 2e-16 *** ## wt -5.3445 0.5591 -9.559 1.29e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.046 on 30 degrees of freedom ## Multiple R-squared: 0.7528, Adjusted R-squared: 0.7446 ## F-statistic: 91.38 on 1 and 30 DF, p-value: 1.294e-10 The summarized result provides details about the model results, such as the coefficients and p-values, the model’s \\(R^2\\), etc. Based on the information, we could know that the estimated coefficient for the interscept is 37.29, its p-value is \\(&lt; 2e-16\\) with a mark \\(***\\), showing it is significant at 99.9% level. The estimated coefficient for mpg is -5.34, its p-value is \\(1.29e-10\\) with a mark \\(***\\), showing it is significant at 99.9% level. We could also know the \\(R^2\\) is 0.75, and adjusted \\(R^2\\) is 0.74. We could use the codes below to check the \\(R^2\\) of the model directly. summary(lm_fit)$r.squared # value of R2 ## [1] 0.7528328 And get the values of the coefficients directly. coefficients(lm_fit) # only check the coefficient ## (Intercept) wt ## 37.285126 -5.344472 Most of the time, we need to examine the relationship between the dependent variable and more than one independent variables. In this case, drawing a plot to check the relationship before the analysis is not a good idea. We just do the regression dicrectly. The example below examines the relationship between mpg and disp, hp, and wt. when there is more than one independent variables, we use + to connect them in the formula. mlm_fit &lt;- lm(mpg ~ disp + hp + wt, mtcars) summary(mlm_fit) ## ## Call: ## lm(formula = mpg ~ disp + hp + wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.891 -1.640 -0.172 1.061 5.861 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.105505 2.110815 17.579 &lt; 2e-16 *** ## disp -0.000937 0.010350 -0.091 0.92851 ## hp -0.031157 0.011436 -2.724 0.01097 * ## wt -3.800891 1.066191 -3.565 0.00133 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.639 on 28 degrees of freedom ## Multiple R-squared: 0.8268, Adjusted R-squared: 0.8083 ## F-statistic: 44.57 on 3 and 28 DF, p-value: 8.65e-11 summary(mlm_fit)$r.squared ## [1] 0.8268361 Again, without careful research design, the relationships shown by the regression model are all correlations, not causalities. 10.3 Logistic regression The above two examples both use continuous variables as their dependent variables. How about using a binomial variable (0 or 1 as its value) a dependent variable? Then we need to do logistic regression. There are many functions to do this. When interpreting the coefficients of the logistic regression result, the coefficient stands for the change of the log odds of the dependent variable to 1. Here, we introduce the glm() function. We need to indicate family = binomial in the function. logit_reg &lt;- glm(am ~ cyl + hp + wt, mtcars, family = binomial) summary(logit_reg) ## ## Call: ## glm(formula = am ~ cyl + hp + wt, family = binomial, data = mtcars) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.17272 -0.14907 -0.01464 0.14116 1.27641 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 19.70288 8.11637 2.428 0.0152 * ## cyl 0.48760 1.07162 0.455 0.6491 ## hp 0.03259 0.01886 1.728 0.0840 . ## wt -9.14947 4.15332 -2.203 0.0276 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 43.2297 on 31 degrees of freedom ## Residual deviance: 9.8415 on 28 degrees of freedom ## AIC: 17.841 ## ## Number of Fisher Scoring iterations: 8 Most of the information is similar with regression ones except that the logistic regression does not have \\(R^2\\) and adjusted \\(R^2\\). It uses AIC (Akaike information criterion) in indicate the goodness of the model. If one model has smaller AIC, it is better. "],
["miscellaneous.html", "Chapter 11 Miscellaneous 11.1 Something related to in-class exercises and grading rubic 11.2 Comparison between R and Stata", " Chapter 11 Miscellaneous 11.1 Something related to in-class exercises and grading rubic Please do remember to submit your codes! Download the codes from Canvas and then start to do the exercises following the instruction in the codes. You do not need to write too-detailed notes, the focus is still coding. Do not write the codes related to the lecture in the exercise, which could help my grading easier. Make sure your codes satisfying the requirements of the exercise. In-class exercise grading rubic (Tentative) Item Grades Codes could generate the results required by the problems 6 Necessary notes to indicate the general idea (usage, function, purpose, or machanism) 3 Codes and notes are neat and well-organized 1 11.2 Comparison between R and Stata As some students asked in class, Why the school still teaches students Stata when no one uses them? I covered several points in class simply which I think is not enough. I think this question is more related to the comparison between R and Stata. I read several articles (Thompson 2019; Bailey 2019) online and list some key points in the table below. I hope this will give a better understanding of both R and Stata. Advantages of R (More Flexible but less Formal) Free and Open source More advanced technique packages Deal with more than one datasets (big data) at the same time Deal with not only data analysis tasks Advantages of Stata (More Formal but less Flexible) More algorithms, packages, and implementations of econometircs Faster It is supported by Statacorp so the result is reliable It presents results in a clear format Syntax is simple and standard for most data analysis Help document is formal Besides those advantages, they have a lot of overlaps with each other. People cannot say one is absolutely better than the other. People choose them based on their task requirements. Sometimes, people install both of them in their computers (e.g. my laptop has both of them). References "],
["final-project.html", "Chapter 12 Final Project 12.1 Description 12.2 Timeline 12.3 Proposal 12.4 Data analysis 12.5 Final report", " Chapter 12 Final Project 12.1 Description R is the tool serving for data analysis and results descprition. In the final project, you will use the R programming skills you learn from this course and also the knowledge outside the course (other R techniques you are interested in or your professional knowledge in your study major) to solve a research question. The research question could be related your study field (e.g. public policy, urban and regional planning), or what you are interested, or your previous course or research project but you do it with R. You could use any packages in R to solve the problem. For example, you could use plots to do descriptive analysis. Or you could use regression to find more complicated correlation or causality results. 12.2 Timeline To accomplish the final project, you need to finish three tasks. Task Descriptions Due Date 1 Proposal Your research question and background introduction 5th Nov. 2 Data analysis The results for data manipulation and data visualization 3th Dec. 3 Final report A short report of your project 22nd Dec. 12.3 Proposal In this part, you will need to submit the proposal file (either word or pdf). The instructor will give you feedback but will not grade this part. The rubic is just for helping you check the requirements. Item Research question and description of research question is clear Background introduction is related to the research topic and could support that the research question is valid and meaningful Clearly state the data sources (what is the dataset, where do you find it, what variables you will use from this dataset) State the potential method you will use for data analysis (descriptive analysis, simple regression, etc.) The proposal should be less than one page (not including citation), 12 font size, and single space. 12.4 Data analysis In this part you will submit your dataset, codes, and the file (either word or pdf) including the figures generated by the codes, the tables, and results descripiton in bullet points. Again, the instructor will give you feedback but will not grade this part. The rubic is just for helping you check the requirements. Item Codes could generate the results Necessary notes for the codes Codes is neat and well-organized Figures contain the necessary parts, well-organized, and visually good/ tables are well-organized Description of the result is clear 12.5 Final report In this part, you will submit your dataset, revised codes, and the final report. The instructor will grade them based on the rubic below. The report should include introduction, data descripition, method (if necessary), result, and conclusion. Category Item Grades Codes Codes could generate the results (figures, tables, and related numbers) 25 Necessary notes for the codes 10 Codes is neat and well-organized 10 Report Research question and description of research question is clear 5 Background introduction is related to the research topic and could support that the research question is valid and meaningful 5 Clearly state the data sources (what is the dataset, where do you find it, what variables you use from this dataset) 5 Variable description is provided and well-organized 5 Figures contain the necessary parts, well-organized, and visually good/ tables are well-organized 25 Description of the result is clear 5 Conclusion is clear, the results are summaried, and implication is meaningful 5 The final report should be less than three pages (not including citation, tables, and figures), 12 font size, and single space. "],
["references.html", "Chapter 13 References", " Chapter 13 References "]
]
